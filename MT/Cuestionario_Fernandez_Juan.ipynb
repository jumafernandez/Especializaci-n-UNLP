{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cuestionario-Fernandez_Juan.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/UNLP/blob/master/MT/Cuestionario_Fernandez_Juan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2N7Mww3nsYi",
        "colab_type": "text"
      },
      "source": [
        "# Cuestionario Final: Minería de Textos\n",
        "\n",
        "En esta notebook se responden a las consignas del cuestionario propuesto para aprobar el curso Minería de Textos de la Especialización en Inteligencia de Datos con orientación en Big Data de la Universidad Nacional de La Plata.\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "__Estudiante:__ Juan Manuel Fernandez, <br />\n",
        "__DNI:__ 30.939.704.\n",
        "\n",
        "## Parte A: Pre-procesamiento de Textos\n",
        "### Tokenización\n",
        "__1. Dé el vocabulario (y su tamaño) que se generaría cuando la tokenización se realiza por palabra (1-grama), bigrama de palabras y\n",
        "5-gramas de caracteres.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb-0-uASniyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "19b35d29-763d-4906-ce97-7a1d71f201c8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Se define el corpus\n",
        "frase = [\"su auto grande pasó velozmente\", \"tu auto rojo es más caro\"]\n",
        "print(\"frase:{}\\n\".format(frase))\n",
        "\n",
        "# Se muestra el vocabulario y su tamaño para una tokenización de 1-grama (por palabra)\n",
        "cv = CountVectorizer(ngram_range=(1, 1)).fit(frase)\n",
        "print(\"Tamaño de vocabulario: {}\".format(len(cv.vocabulary_)))\n",
        "print(\"Vocabulario:{}\".format(cv.get_feature_names()))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Se muestra el vocabulario y su tamaño para una tokenización de bigrama (2 palabras)\n",
        "cv = CountVectorizer(ngram_range=(2, 2)).fit(frase)\n",
        "print(\"Tamaño de vocabulario: {}\".format(len(cv.vocabulary_)))\n",
        "print(\"Vocabulario:\\n{}\".format(cv.get_feature_names()))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Se muestra el vocabulario y su tamaño para una tokenización de 5-gramas de char (5 char)\n",
        "cv = CountVectorizer(analyzer='char',ngram_range=(5, 5)).fit(frase)\n",
        "print(\"Tamaño de vocabulario: {}\".format(len(cv.vocabulary_)))\n",
        "print(\"Vocabulario:\\n{}\".format(cv.get_feature_names()))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frase:['su auto grande pasó velozmente', 'tu auto rojo es más caro']\n",
            "\n",
            "Tamaño de vocabulario: 10\n",
            "Vocabulario:['auto', 'caro', 'es', 'grande', 'más', 'pasó', 'rojo', 'su', 'tu', 'velozmente']\n",
            "\n",
            "\n",
            "Tamaño de vocabulario: 9\n",
            "Vocabulario:\n",
            "['auto grande', 'auto rojo', 'es más', 'grande pasó', 'más caro', 'pasó velozmente', 'rojo es', 'su auto', 'tu auto']\n",
            "\n",
            "\n",
            "Tamaño de vocabulario: 43\n",
            "Vocabulario:\n",
            "[' auto', ' caro', ' es m', ' gran', ' más ', ' pasó', ' rojo', ' velo', 'ande ', 'asó v', 'auto ', 'de pa', 'e pas', 'elozm', 'es má', 'grand', 'jo es', 'lozme', 'mente', 'más c', 'nde p', 'o es ', 'o gra', 'o roj', 'ojo e', 'ozmen', 'pasó ', 'rande', 'rojo ', 's car', 's más', 'su au', 'só ve', 'to gr', 'to ro', 'tu au', 'u aut', 'uto g', 'uto r', 'veloz', 'zment', 'ás ca', 'ó vel']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmZ9bsMNq83q",
        "colab_type": "text"
      },
      "source": [
        "__2. Dé su opinión de cuales serían las limitaciones de la primera forma de particionado (1-grama) y los posibles patrones que permitiría\n",
        "capturar los restantes dos enfoques.__ \n",
        "\n",
        "Las limitaciones del 1-grama residen en que, por un lado, no puede capturar el contexto de la palabra que si se lograría a través de un n-grama (con n>1) de palabras y en que, por otro lado, no tenemos forma de tomar la \"raíz\" de la palabra sin aplicar alguna técnica adicional (como stemming o lematización), cuestión que si podría lograrse a partir de n-gramas de caracteres.<br /> <br />\n",
        "\n",
        "__3. El uso de 3-gramas de caracteres es un enfoque que ha dado buenos\n",
        "resultados en el idioma inglés. ¿Considera usted que en el español podría ser mejor utilizar un número n distinto de caracteres contiguos? Justifique.__  \n",
        "\n",
        "La cantidad de n-gramas de caracteres \"óptima\" puede variar dado que no solo del idioma del texto sino que, además, puede variar dentro del mismo idioma para contextos distintos. !!!COMPLETAR!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yFIYgarlJhm",
        "colab_type": "text"
      },
      "source": [
        "### Normalización (truncado y lematización) y POS-tagging\n",
        "\n",
        "__1. Utilizando alguno de los \"stemmers on-line\" provistos en el sitio http://textanalysisonline.com/ (por ejemplo http://textanalysisonline.com/nltk-porter-stemmer), chequee cual sería el resultado que el stemmer de Porter arrojaría para la cadena:\n",
        "_\"Some housewives felt scared when they heard a lot of mice\"___ \n",
        "\n",
        "El resultado de aplicar el stemmer de Porter es _\"Some housew felt scare when they heard a lot of mice\"_. Básicamente, los tokens que modifica son _housewives_ por _housew_ y _scared_ por _scare_.\n",
        "<br /> <br />\n",
        "\n",
        "__2. Describa cual sería el resultado que a su criterio produciría un\n",
        "sistema de lematización con la misma cadena.__  <br /> <br />\n",
        "\n",
        "__3. Describa y explique cual es el resultado que el POS-tagger online de spaCy (disponible en http://textanalysisonline.com/spacy-pos-tagging) produce con la misma cadena.__  \n",
        "\n",
        "El resultado que arroja el POS-tagger es el siguiente:\n",
        "\"Some|DET housewives|NOUN felt|VERB scared|ADJ when|ADV they|NOUN heard|VERB a|DET lot|NOUN of|ADP mice|NOUN\".\n",
        "\n",
        "<br /> <br />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRa7GZ_TjYNQ",
        "colab_type": "text"
      },
      "source": [
        "### Sentidos de las palabras y Wordnet\n",
        "__1. Defina con sus palabras a qué se denomina synset en Wordnet, y en\n",
        "que consisten las relaciones semánticas de hiperonimia, hiponimia y meronimia.__\n",
        "<br /><br />\n",
        "__2. Descargando y utilizando el sistema Wordnet 2.1 disponible en https://wordnet.princeton.edu/download, determine a que distancia (en número de conceptos recorridos) se encuentra el primer sentido del sustantivo (noun) nose del concepto organ siguiendo la relación de hiperonimia (\"es una clase de\") y a que distancia del concepto de body siguiendo la relación de holonimia (\"es una\n",
        "parte de\"). A modo de ejemplo: si buscamos la palabra cat (gato) y usamos el botón \"Noun\" para ver las distintas relaciones semánticas como sustantivo, veremos que siguiendo la relación de hiperonimia, \"cat\" se encuentra a una distancia de 5 (5 saltos) en la relación de hiperonimia, dada por la siguiente secuencia: cat ⇒ feline ⇒ carnivore ⇒ placental ⇒ mammal ⇒ vertebrate.__\n",
        "<br /><br />\n",
        "\n",
        "### Reconocimiento de Entidades nombradas\n",
        "\n",
        "__Utlizando el reconocedor de entidades nombradas de spaCy disponible en http://textanalysisonline.com/spacy-named-entity-recognition-ner, describa cual es el resultado del mismo al aplicarlo a las siguientes sentencias: <br/>\n",
        "\"Washinton was born into slavery on the farm of James Burroughs.\" <br/>\n",
        "\"In June, Washington passed a primary seatbelt law.\" <br/>\n",
        "Explique además el porqué del etiquetado diferente de Washington en\n",
        "los dos casos.__  <br/> <br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byJkt-ynjYlT",
        "colab_type": "text"
      },
      "source": [
        "## Parte B: Representación de documentos"
      ]
    }
  ]
}